
쿠버네티스 - Volume Object 제공 -> PVC

볼륨 솔루션 / Kubernetes Native Storage <- 플러그인 역할 - PV

볼륨 솔루션 (AWS EBS, Storage OS... )
Kubernetes Native Storage (ROOK, MINIO, ...)

---
# PVC, PV

> Container 안에만 파일을 만들어두면, Pod가 죽었을 때 파일도 같이 삭제 되므로, 
> 외부인 PV를 연결해서 쓴다 

## 왜 PVC, PV를 써야 하는가 
1. Pod 만드는 주체 : 개발자  -> storage 솔루션까지 알기 힘들다 
	- 따라서, 인프라 담당자가 PV 오브젝트 만들어서  PVC (개발자; Pod에서 필요한 자원을 요청하는 용도로 만듦)를 만드는 데 사용 
2. Pod는 휘발성으로 삭제되면 데이터도 같이 삭제된다. 이를 방지하기 위해 PV를 붙여야 한다 

## PVC와 PV의 주요 필드 관계  관계 

- Pod의 volumes에 PVC 연결 
- `PVC.resources.requests.storage` ↔ `PV.capacity.storage` (용량 일치)
- `PVC.accessModes` ↔ `PV.accessModes` (접근 모드 일치)
- `PVC.selector` ↔ `PV.labels` (라벨 일치)

## PVC, PV - [local](https://kubernetes.io/ko/docs/concepts/storage/volumes/#local) 의 path

- local 사용 -> [nodeAffinity](https://kubernetes.io/ko/docs/tasks/configure-pod-container/assign-pods-nodes-using-node-affinity/) 속성 필수 사용  (어느 Node에 Pod를 생성할지 지정)


- pv, pvc를 안쓰고 pod에서 바로 연결 (hostpath 방식) 이랑 local 방식 

1. 가능하면 [hostPath](https://kubernetes.io/ko/docs/concepts/storage/volumes/#hostpath)를 사용하지 말기 
2. 노드의 정보를 이용해야 하는 기능의 app
3. 테스트 환경에서 임시 저장 용도로 사용 
	- 운영환경 X
	- 노드 공간 부족 -> 죽을 수 있음 
	- 노드는 언제든지 죽을 수 있음



[[7.1. 실습1 - PV와 PVC 기능 이해하기]]

---
# Deployment (Recreate, RollingUpdate-maxUnavailable, maxSurge)

- Pod 템플릿이 바뀌면 새로운 ReplicaSet 생성됨
- 이전 ReplicaSet은 **rollback 용도**로 보관됨

> strategy 의 Recreate, RollingUpdate 2가지 방식이 있음 

## Object 에서 업데이트 
template 변경 -> 업데이트 

새로운 이름의 ReplicaSet을 만들고 Pod를 replicas 수만큼 만든다
-> 기존 ReplicaSet의 Pod들은 삭제되고, replicas 는 0으로 된다 
(기존 ReplicaSet은 rollback해야 할 때 사용된다)

- 운영환경에서는 자원이 많이 증가되는게 쉽게 생각할 문제가 아님 
- 무중단 배포가 필요한지 고려 

1. RollingUpdate
	1. 기본
	2. maxUnavailable, maxSurge 변경
2. Recreate
3. Rollback

### 1. RollingUpdate # 기본 설정 
- 새버전 Pod를 하나 만들고, 기동이 완료되면 기존 Pod를 삭제함 x 2 
- 무중단 배포 
- 자원 사용량 150% 증가 
- 또한, 두 버전이 동시에 호출되는 문제가 있음

- `maxUnavailable` : 25% # 업데이트 동안 `최대 몇 개 Pod를 서비스 상태로 유지`할지 
	-  0% : 서비스 중에 부하를 유지해야 하기 때문에 업데이트를 하는 동안에도 Pod 개수를 감소시키지 않겠다 
- `maxSurge` : 25% # 새 Pod를 최대 몇개까지 동시에 만들지 

- 예시 
	- 100%, 100% -> Recreate와 같은 효과 
	- 0%, 100% ->  Blue Green에 가까운 효과 

### 2. Recreate
- 기존 Pod 2개 삭제 -> 새 Pod 2개 만듦 
-> Pod들은 처리되는 속도에 따라 기동시간이 다름
-> 첫번째 Pod의 기동시간 만큼 서비스가 중단 됨

### 3. Blue/Green 
- 다 Green을 만든다음 한번에 Blue 트래픽을 Green으로 변경하는 방식
- 자원 사용량 200% 증가
- 별도 배포 솔루션에서 제공 

[[7.2. 실습2 - Deployment]]

---
# Service - Discovery, Publising, Registry, Load Balancing

### 주요 속성 
- Service : 
	- selector # 어떤 Pod를 대상으로 할 것인지 
	- type # 서비스 노출 방식 
		- Default : ClusterIP 
	- ports # 외부 -> 내부 트래픽 매핑 설정 
		- protocol
		- targetPort
		- nodePort

### 서비스 타입 
- NodePort : 외부에서 보낸 트래픽이 Pod로 전달됨  
	- Pod의 컨테이너를 보면 APP이 기동한 후에 호출을 할 수 있는 API와 Port가 노출되어 있음 
	- 서비스 퍼블리싱 : 외부에서 Pod로 트래픽 연결 용도 

- clusterIP (기본)
	- 쿠버네티스 내부에 Pod에서만 접근하는 용도
	- 내부 DNS로 호출: `service-name.namespace.svc.cluster.local`



### ClusterIP와 서비스 디스커버리 

> Pod의 IP는 휘발성이므로, Service로 접근해야 함  
> Service가 내부 DNS와 함께 IP 추상화를 제공함


- service의 port라는 필수 속성
	- service 이름이랑 80포트를 넣어 API를 호출하면 내부적으로 targetPort로 포워딩되서 트래픽이 Pod로 전달됨 

- 서비스 디스커버리 :  내부 DNS를 이용한 Service 이름으로 API 호출 
	- cluster 의 다른 Namespace에 있는 Pod가 호출을 할 때는 Service 이름 뒤에 namespace이름까지 붙여줘야함 


실질적인 Pod 의 Container Port가 바뀌더라도 containers.ports.name, containers.ports.containerPort를 입력해두면, Service의 ports.targetPort 속성과 일치하는 값을 찾아 연결해줌 


[[7.3 실습3 - Service -search]]

---
# HPA 

- 요청 처리량/리소스 사용량을 기준으로 **Pod 개수를 자동 조정**함


Deployment.resource
- requests에 cpu : 100m , memory가 지정되어 있는데, 설정된 값이 100% 계산을 위한 기준 값 
- limits 에 따라 올라갈 수 있는 최대 퍼센트가 지정됨 

HPA의 metrics에 averageUtilization 속성
behavior : 잦은 스케일링 방지 
scaleUp: stabilizationWindowSeconds: 120 # 2분 동안 60% 유지시 scaleOut


현재 Pod 수 * (평균 CPU / HPA CPU) -> 변경될 Pod수 
2 * (((150 + 1)/ 2) / 60) = 3 (2.51)


부하 중이라고 판단하는 기준이 다르기에 CPU만으로 부하라고 생각할 수 없음
-> CPU 올라가기 전에 DB Connection 수가 부족해서 Pod를 늘려야 할 수도 있음 



[[7.4. 실습4 - HPA - search]]


